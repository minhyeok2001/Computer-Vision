{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":16017,"databundleVersionId":708189,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# 경로 확인\ntrain_csv_path = '/kaggle/input/Kannada-MNIST/train.csv'\ntest_csv_path = '/kaggle/input/Kannada-MNIST/test.csv'\n\n# 데이터 로드\ntrain_data = pd.read_csv(train_csv_path)\ntest_data = pd.read_csv(test_csv_path)\n\nimport torch\n\ntrain_images = []\ntrain_labels = []\n\n# 각 행에서 데이터를 추출\nfor idx in range(len(train_data)):\n    # 라벨 추출\n    label = train_data.iloc[idx,0]\n    train_labels.append(label)\n    \n    # 픽셀 데이터 추출\n    pixels = train_data.iloc[idx,1:].values.reshape((1, 28, 28))\n    train_images.append(pixels)\n\ntest_images = []\ntest_labels = []\n\nfor idx in range(len(test_data)):\n    # 라벨 추출\n    label = test_data.iloc[idx,0]\n    test_labels.append(label)\n    \n    pixels = test_data.iloc[idx,1:].values.reshape((1, 28, 28))\n    test_images.append(pixels)\n\n# train_images, train_labels 리스트를 NumPy 배열로 변환 후 텐서로 변환\ntrain_images = np.array(train_images)  # 리스트 -> NumPy 배열\ntrain_labels = np.array(train_labels)  # 리스트 -> NumPy 배열\n\ntrain_images = torch.tensor(train_images, dtype=torch.float32)  # NumPy -> 텐서\ntrain_labels = torch.tensor(train_labels, dtype=torch.long)     # NumPy -> 텐서\n\n# test_images, test_labels도 같은 방식으로 변환\ntest_images = np.array(test_images)  # 리스트 -> NumPy 배열\ntest_images = torch.tensor(test_images, dtype=torch.float32)  # NumPy -> 텐서\ntest_labels = np.array(test_labels)  # 리스트 -> NumPy 배열\ntest_labels = torch.tensor(test_labels, dtype=torch.long)  # NumPy -> 텐서\n\ntrain_set = torch.utils.data.TensorDataset(train_images, train_labels)\ntest_set = torch.utils.data.TensorDataset(test_images, test_labels)\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)\n\n\nimport torch.nn as nn\nclass CNN(nn.Module):\n  def __init__(self):\n    super(CNN, self).__init__()\n    self.k1 = nn.Conv2d(1,16,kernel_size=3,padding=1)\n    self.k2 = nn.Conv2d(16,8,kernel_size=3)\n    self.k3 = nn.Conv2d(8,4,kernel_size=2)\n    self.fc = nn.Linear(4*2*2,10)\n    self.pool = nn.AvgPool2d(2,2)\n    self.act = nn.ReLU() \n    self.dropout = nn.Dropout(0.2)\n\n  def forward(self,x):\n    x = self.k1(x)\n    x = self.act(x)\n    x = self.pool(x)\n    \n    x = self.k2(x)\n    x = self.act(x)\n    x = self.pool(x)\n    \n    x = self.k3(x)\n    x = self.act(x)\n    x = self.pool(x)\n\n    x = x.view(x.size(0),-1)\n    x = self.fc(x)\n    return x\n\nmodel = CNN()\nmodel.train()\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nfor epoch in range(5):\n  for input, labels in train_loader:\n      y = model(input)\n      loss = loss_fn(y,labels)\n      optimizer.zero_grad()\n      loss.backward()\n      optimizer.step()\n\nmodel.eval()\n\ncorrect = 0\ntotal = 0\n\npredictions = []  # 모든 예측을 저장할 리스트\n\nwith torch.no_grad():\n    for input, _ in test_loader:  # 테스트 데이터에는 라벨이 없으므로 무시\n        outputs = model(input)\n        predicted = torch.argmax(outputs, dim=1)\n        predictions.extend(predicted.cpu().numpy())  # 모든 배치의 예측을 누적\n\n# 테스트 데이터의 ID 생성\ntest_ids = list(range(len(predictions)))  # ID는 0부터 시작하는 순서\n\n# 예측 결과를 DataFrame으로 생성\nsubmission = pd.DataFrame({\n    'id': test_ids,        # 테스트 데이터의 ID\n    'label': predictions   # 모델의 예측 결과\n})\n\n# CSV 파일로 저장\nsubmission.to_csv('submission.csv', index=False)\n\nprint(\"Submission file 'submission.csv' has been created.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T08:31:23.610993Z","iopub.execute_input":"2025-01-12T08:31:23.611423Z","iopub.status.idle":"2025-01-12T08:32:39.724245Z","shell.execute_reply.started":"2025-01-12T08:31:23.611392Z","shell.execute_reply":"2025-01-12T08:32:39.723083Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/Kannada-MNIST/sample_submission.csv\n/kaggle/input/Kannada-MNIST/Dig-MNIST.csv\n/kaggle/input/Kannada-MNIST/train.csv\n/kaggle/input/Kannada-MNIST/test.csv\nSubmission file 'submission.csv' has been created.\n","output_type":"stream"}],"execution_count":13}]}